# -*- coding: utf-8 -*-
"""Proyek Analisis Data Notebook

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qBDEy8wg8IYoauY52C8bhdNYP0_tRSls

# Proyek Analisis Data: [E-Commerce Public Dataset]
- **Nama:** [Halilatunnisa]
- **Email:** [halilatunnisa08@gmail.com]
- **ID Dicoding:** [halilatunnisa]

## Menentukan Pertanyaan Bisnis

- Produk mana yang memberikan kontribusi pendapatan terbesar berdasarkan total nilai transaksi selama periode Januari 2017 – Desember 2017?
- Wilayah geografis mana yang memiliki konsentrasi pelanggan tertinggi berdasarkan jumlah customer_unique_id selama periode Januari 2017 – Desember 2017?

## Import Semua Packages/Library yang Digunakan
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import urllib
import matplotlib.image as mpimg
from scipy import stats
import os

"""## Data Wrangling

### Gathering Data
"""

from google.colab import drive
drive.mount('/content/drive')

base_path = "/content/drive/MyDrive/Kuliah/E-Commerce Public Dataset/"

file_names = {
    "orders": "orders_dataset.csv",
    "order_items": "order_items_dataset.csv",
    "products": "products_dataset.csv",
    "payments": "order_payments_dataset.csv",
    "reviews": "order_reviews_dataset.csv",
    "customers": "customers_dataset.csv",
    "sellers": "sellers_dataset.csv",
    "geolocation": "geolocation_dataset.csv",
    "category_translation": "product_category_name_translation.csv"
}

data = {key: pd.read_csv(os.path.join(base_path, value))
        for key, value in file_names.items()}

data['orders'].head()

data['order_items'].head()

data['products'].head()

data['payments'].head()

data['reviews'].head()

data['customers'].head()

data['sellers'].head()

data['geolocation'].head()

data['category_translation'].head()

"""### Assessing Data

Periksa Tipe data
"""

for df_name, df in data.items():
  print('\n', data[df_name].info())

data["orders"]["order_purchase_timestamp"] = pd.to_datetime(
    data["orders"]["order_purchase_timestamp"]
)

# Filter periode setelah datetime dikonversi
orders_filtered = data["orders"][
    (data["orders"]["order_purchase_timestamp"] >= "2017-01-01") &
    (data["orders"]["order_purchase_timestamp"] <= "2017-12-31")
]

order_id_periode = orders_filtered["order_id"].to_numpy()

# Filter seluruh dataset berdasarkan order_id dalam periode
for nama_tabel, df in data.items():
    if "order_id" in df.columns:
        data[nama_tabel] = df[df["order_id"].isin(order_id_periode)]

datetime_columns = {
    "orders": [
        "order_purchase_timestamp",
        "order_approved_at",
        "order_delivered_carrier_date",
        "order_delivered_customer_date",
        "order_estimated_delivery_date"
    ],
    "order_items": ["shipping_limit_date"],
    "reviews": ["review_creation_date", "review_answer_timestamp"]
}

for table, columns in datetime_columns.items():
    for col in columns:
        data[table][col] = pd.to_datetime(data[table][col])

"""Periksa Duplikat"""

jumlah_duplikat = {}
total_data = {}

for nama_df, isi_df in data.items():
    jumlah_duplikat[nama_df] = isi_df.duplicated().sum()
    total_data[nama_df] = isi_df.shape[0]

df_duplikat = pd.DataFrame(jumlah_duplikat.items(),
                           columns=["Dataset", "Jumlah Duplikat"]).set_index("Dataset")

df_total = pd.DataFrame(total_data.items(),
                        columns=["Dataset", "Total Data"]).set_index("Dataset")

hasil_ringkasan = df_total.join(df_duplikat)

hasil_ringkasan

"""Periksa Missing Value"""

jumlah_null = {}

for nama, df in data.items():
    total_null = df.isnull().sum()
    jumlah_null[nama] = total_null

    print(f"Dataset: {nama}")
    print(total_null)
    print("-" * 40)

"""### Cleaning Data

Order
"""

# Untuk analisis ini, hanya fokus pada pesanan yang sudah terkirim
status_pesanan = data["orders"]["order_status"].value_counts()

print(status_pesanan)

# Menghitung persentase order dengan status delivered
total_order = len(data["orders"])
jumlah_delivered = data["orders"]["order_status"].value_counts()["delivered"]

persentase_delivered = round((jumlah_delivered / total_order) * 100, 2)

print(f"Jika hanya mengambil pesanan yang delivered, kita masih memiliki {persentase_delivered}% dari total data.")

# Ambil daftar order_id yang bukan delivered
order_tidak_terkirim = data["orders"].loc[
    data["orders"]["order_status"] != "delivered",
    "order_id"
].to_numpy()

# Hapus baris pada setiap dataset yang memiliki order_id tersebut
for nama_tabel, df in data.items():
    if "order_id" in df.columns:
        data[nama_tabel] = df[~df["order_id"].isin(order_tidak_terkirim)]

# Persentase nilai kosong di setiap kolom
for nama_df, df in data.items():
    for nama_kolom in df.columns:
        jumlah_kosong = df[nama_kolom].isna().sum()

        if jumlah_kosong > 0:
            persen_kosong = (jumlah_kosong / df.shape[0]) * 100
            print(f"{nama_df} - {nama_kolom} (%): {persen_kosong}")

jumlah_tanpa_tanggal_kirim = data["orders"]["order_delivered_customer_date"].isna().sum()

print(f"Terdapat {jumlah_tanpa_tanggal_kirim} pesanan yang belum memiliki tanggal pengiriman.")

# Ambil order_id yang tidak memiliki tanggal sampai ke customer
order_tanpa_tanggal = data["orders"].loc[
    data["orders"]["order_delivered_customer_date"].isna(),
    "order_id"
].to_numpy()

# Hapus baris terkait di seluruh tabel yang memiliki kolom order_id
for nama_df, df in data.items():
    if "order_id" in df.columns:
        indeks_hapus = df[df["order_id"].isin(order_tanpa_tanggal)].index
        df.drop(index=indeks_hapus, inplace=True)

# Membuat indikator apakah pesanan sampai tepat waktu atau tidak
orders_df = data["orders"]

orders_df["status_ketepatan"] = np.where(
    orders_df["order_delivered_customer_date"]
    < orders_df["order_estimated_delivery_date"],
    "On Time",
    "Late"
)

"""Reviews"""

# Melihat daftar kolom pada dataset reviews
print("Kolom pada dataset reviews:", list(data["reviews"].columns))

# Kolom review_comment_title memiliki banyak nilai kosong, jadi dihapus
kolom_dihapus = ["review_comment_title"]

data["reviews"] = data["reviews"].drop(columns=kolom_dihapus)

# Jika tidak ada komentar = 0, jika ada komentar = 1

reviews_df = data["reviews"]

reviews_df["indikator_komentar"] = (
    reviews_df["review_comment_message"]
    .notna()
    .astype(int)
)

# Menggabungkan payments dengan reviews berdasarkan order_id
gabungan_payment_review = data["payments"].merge(
    data["reviews"],
    on="order_id",
    how="left"
)

# Membuat indikator: jika ada komentar = 1, jika tidak = 0
gabungan_payment_review["review_comment_message"] = (
    gabungan_payment_review["review_comment_message"]
    .notna()
    .astype(int)
)

gabungan_payment_review.head()

"""Products"""

# Menampilkan daftar kolom pada dataset products
print("Kolom pada dataset products:", list(data["products"].columns))

# Menghapus kolom yang tidak digunakan dalam analisis
kolom_tidak_dipakai = [
    "product_name_lenght",
    "product_description_lenght",
    "product_weight_g",
    "product_length_cm",
    "product_height_cm",
    "product_width_cm"
]

data["products"] = data["products"].drop(columns=kolom_tidak_dipakai)

# Mengganti nilai kosong pada kategori produk menjadi 'outro'
data["products"]["product_category_name"] = (
    data["products"]["product_category_name"]
    .fillna("outro")
)

# Mengisi nilai kosong pada jumlah foto produk dengan 0
data["products"]["product_photos_qty"] = (
    data["products"]["product_photos_qty"]
    .fillna(0)
)

"""Geolocations"""

# Menghapus baris duplikat pada dataset geolocation
data["geolocation"] = data["geolocation"].drop_duplicates()

"""## Exploratory Data Analysis (EDA)

### Explore Customer
"""

data['customers'].sample(10)

jumlah_customer_kota = (
    data["customers"]
    .groupby("customer_city")["customer_id"]
    .nunique()
    .sort_values(ascending=False)
)

jumlah_customer_kota

jumlah_customer_state = (
    data["customers"]
    .groupby("customer_state")["customer_id"]
    .nunique()
    .sort_values(ascending=False)
)

jumlah_customer_state

"""### Explore payments"""

data['payments'].sample(10)

jumlah_order_per_payment = (
    data["payments"]
    .groupby("payment_type")["order_id"]
    .nunique()
    .sort_values(ascending=False)
)

jumlah_order_per_payment

"""### Explore orders"""

data['orders'].sample(10)

ringkasan_ketepatan = data["orders"]["status_ketepatan"].describe()
ringkasan_ketepatan

"""### Explore customers dan orders"""

# Menggabungkan data customers dengan orders berdasarkan customer_id
gabungan_customer_order = data["customers"].merge(
    data["orders"],
    on="customer_id",
    how="left"
)

gabungan_customer_order.head()

gabungan_payment_review["review_comment_message"] = (
    gabungan_payment_review["review_comment_message"]
    .notna()
    .astype(int)
)

gabungan_payment_review.head()

payments_reviews_df = gabungan_payment_review.copy()

# Urutkan berdasarkan nilai pembayaran
payments_reviews_df.sort_values(by="payment_value", ascending=False).head()

payments_reviews_df.groupby(by="payment_type").agg({
    "order_id": "nunique",
    "payment_value":  ["min", "max"]
})

# Menggabungkan data customer-orders dengan payment-review berdasarkan order_id
customers_df = gabungan_customer_order.merge(
    payments_reviews_df,
    on="order_id",
    how="left"
)

customers_df.head()

"""### Explore items dan sellers"""

# Menggabungkan order_items dengan sellers
item_seller_df = pd.merge(
    left=data['order_items'],
    right=data['sellers'],
    how="left",
    on="seller_id"
)

item_seller_df.head()

item_seller_df.groupby(by="seller_city").seller_id.nunique().sort_values(ascending=False).head(10)

item_seller_df.groupby(by="seller_state").seller_id.nunique().sort_values(ascending=False).head(10)

"""###Explore products dan category"""

# Menggabungkan products dengan category translation
product_df = pd.merge(
    left=data['products'],
    right=data['category_translation'],
    how="left",
    on="product_category_name"
)

product_df.head()

product_df.groupby(by="product_category_name").product_id.nunique().sort_values(ascending=False).head(10)

product_df.groupby(by="product_category_name_english").product_id.nunique().sort_values(ascending=False).head(10)

# Menggabungkan product_df dengan item_seller_df
sellers_df = pd.merge(
    left=product_df,
    right=item_seller_df,
    on="product_id",
    how="left"
)

sellers_df.head()

sellers_df.sort_values(by="price", ascending=False)

kategori_summary = sellers_df.groupby("product_category_name_english").agg({
    "order_id": "nunique",
    "price": ["min", "max"]
}).reset_index()

kategori_summary

"""###Explore geolocation"""

data['geolocation'].sample(10)

jumlah_per_zip = data['geolocation'].groupby('geolocation_zip_code_prefix').size().sort_values(ascending=False)

jumlah_per_zip

# Tampilkan beberapa baris geolocation untuk kode pos 24230
data['geolocation'][data['geolocation']['geolocation_zip_code_prefix'] == 24230].head()

"""###Explore Semua Data"""

# Ambil hanya informasi kategori produk per order
order_category = sellers_df[["order_id", "product_category_name_english"]].drop_duplicates()

# Gabungkan dengan customers_df
all_data = customers_df.merge(
    order_category,
    on="order_id",
    how="left"
)

all_data.head()

provinsi_summary = all_data.groupby("customer_state").agg({
    "order_id": "nunique",
    "payment_value": "sum"
}).sort_values(by="payment_value", ascending=False).reset_index()

provinsi_summary

kategori_summary = all_data.groupby("product_category_name_english").agg({
    "order_id": "nunique",
    "review_score": ["min", "max"]
}).reset_index()

kategori_summary

output_csv_path = "/content/drive/MyDrive/Kuliah/E-Commerce Public Dataset/df.csv"

# Simpan dataframe all_data ke CSV
all_data.to_csv(output_csv_path, index=False)

"""## Visualization & Explanatory Analysis

### Pertanyaan 1: Produk mana yang memberikan kontribusi pendapatan terbesar berdasarkan total nilai transaksi selama periode Januari 2017 – Desember 2017?
"""

items_product = data['order_items'].merge(
    data['products'],
    on='product_id',
    how='inner'
)

orders_ip = data['orders'].merge(
    items_product,
    on='order_id',
    how='inner'
)

orders_ip = orders_ip.merge(
    data['category_translation'],
    on='product_category_name',
    how='left'
)

# Group by English category name
product_revenue = orders_ip.groupby('product_category_name_english').agg(
    quantity_sold=('order_item_id', 'count'),
    total_revenue=('price', 'sum')
).reset_index()

top10_products = product_revenue.sort_values(
    by='total_revenue',
    ascending=False
).head(10)

plt.figure(figsize=(10,6))
bars = plt.barh(
    top10_products['product_category_name_english'],
    top10_products['total_revenue'],
    color='skyblue'
)

plt.xlabel("Total Revenue (R$)")
plt.ylabel("Product Category")
plt.title("Top 10 Product Categories by Revenue (Jan 2017 – Dec 2017)")
plt.gca().invert_yaxis()

for bar in bars:
    width = bar.get_width()
    plt.text(
        width,
        bar.get_y() + bar.get_height()/2,
        f'{width:.0f}',
        va='center',
        ha='left'
    )
plt.savefig("/content/drive/MyDrive/Kuliah/E-Commerce Public Dataset/top10_products_revenue.png", dpi=300)
plt.show()

"""### Pertanyaan 2: Wilayah geografis mana yang memiliki konsentrasi pelanggan tertinggi berdasarkan jumlah customer_unique_id selama periode Januari 2017 – Desember 2017?"""

# Hitung jumlah state unik per kode pos
other_state_geolocation = data['geolocation'].groupby('geolocation_zip_code_prefix')['geolocation_state'] \
                        .nunique().reset_index(name='count')

# Tampilkan jumlah kode pos yang memiliki >= 2 state
other_state_geolocation[other_state_geolocation['count'] >= 2].shape

# Ambil 1 state saja per kode pos (menghapus duplikat)
max_state = data['geolocation'].groupby(['geolocation_zip_code_prefix', 'geolocation_state']) \
            .size().reset_index(name='count') \
            .drop_duplicates(subset='geolocation_zip_code_prefix') \
            .drop('count', axis=1)

# Hitung median latitude & longitude per kode pos + city + state
geolocation_silver = data['geolocation'].groupby(
    ['geolocation_zip_code_prefix', 'geolocation_city', 'geolocation_state']
)[['geolocation_lat', 'geolocation_lng']].median().reset_index()

# Gabungkan dengan max_state untuk memastikan 1 state per kode pos
geolocation_silver = geolocation_silver.merge(
    max_state,
    on=['geolocation_zip_code_prefix', 'geolocation_state'],
    how='inner'
)

customers_silver = customers_df.merge(
    geolocation_silver,
    left_on='customer_zip_code_prefix',
    right_on='geolocation_zip_code_prefix',
    how='inner'
)

customers_silver.head(10)

customers_silver = customers_silver.drop_duplicates(subset='order_id')

customers_silver.to_csv("/content/drive/MyDrive/Kuliah/E-Commerce Public Dataset/geolocation.csv", index=False)

# Hitung jumlah pelanggan per zip code
customers_zip_count = customers_silver.groupby(
    ['geolocation_zip_code_prefix', 'geolocation_lat', 'geolocation_lng']
)['customer_unique_id'].nunique().reset_index(name='customer_count')

brazil = mpimg.imread(urllib.request.urlopen(
    'https://i.pinimg.com/originals/3a/0c/e1/3a0ce18b3c842748c255bc0aa445ad41.jpg'), 'jpg')

fig, ax = plt.subplots(figsize=(10,10))
sc = ax.scatter(
    customers_zip_count['geolocation_lng'],
    customers_zip_count['geolocation_lat'],
    s=customers_zip_count['customer_count']*2,
    c=customers_zip_count['customer_count'],
    cmap='viridis',
    alpha=0.6,
    edgecolors='w',
    linewidth=0.3
)

ax.imshow(brazil, extent=[-74, -34, -34, 6], aspect='auto', zorder=-1)
ax.set_xlim([-74, -34])
ax.set_ylim([-34, 6])
ax.axis('off')

plt.colorbar(sc, label='Jumlah Pelanggan')
plt.title("Distribusi Pelanggan di Brazil (Jan 2017 – Des 2017)", fontsize=16, pad=20)
plt.savefig("/content/drive/MyDrive/Kuliah/E-Commerce Public Dataset/customer_map.png", dpi=300)
plt.show()

top10_cities = customers_silver.groupby('geolocation_city')['customer_unique_id'] \
               .nunique().sort_values(ascending=False).head(10)

plt.figure(figsize=(10,6))
bars = plt.barh(top10_cities.index[::-1], top10_cities.values[::-1], color='skyblue')

plt.xlabel("Jumlah Pelanggan")
plt.ylabel("Kota")
plt.title("Top 10 Kota dengan Pelanggan Terbanyak (Jan 2017 – Des 2017)")

for bar in bars:
    width = bar.get_width()
    plt.text(
        width,
        bar.get_y() + bar.get_height()/2,
        f'{width:.0f}',
        va='center',
        ha='left'
    )

plt.savefig("/content/drive/MyDrive/Kuliah/E-Commerce Public Dataset/top10_cities.png", dpi=300)
plt.show()

"""## **Conclusion**

*   Produk mana yang memberikan kontribusi pendapatan terbesar berdasarkan total nilai transaksi selama periode Januari 2017 – Desember 2017?
  > Kategori produk bed_bath_table adalah penyumbang pendapatan tertinggi dengan total 490.264 R$. Kategori ini memiliki keunggulan yang cukup signifikan dibandingkan kategori lainnya. Terdapat selisih sekitar 15.965 R$ antara kategori peringkat pertama ini dengan kategori di peringkat kedua (watches_gifts). Mengingat besarnya kontribusi kategori ini terhadap total pendapatan, sangat penting untuk menjaga ketersediaan stok produk-produk dalam kategori bed_bath_table dan mengamankan rantai pasokannya agar pendapatan tidak terganggu.

*   Wilayah geografis mana yang memiliki konsentrasi pelanggan tertinggi berdasarkan jumlah customer_unique_id selama periode Januari 2017 – Desember 2017?
  > Berdasarkan grafik "Top 10 Kota dengan Pelanggan Terbanyak", konsentrasi pelanggan tertinggi secara absolut berada di kota Sao Paulo dengan total 5.903 pelanggan, disusul oleh Rio de Janeiro dengan 3.103 pelanggan. Karena Sao Paulo mendominasi jumlah pelanggan dengan selisih yang sangat signifikan (hampir dua kali lipat dari peringkat kedua), sangat disarankan untuk memusatkan strategi operasional logistik di kota ini. Menempatkan pusat distribusi utama di area Sao Paulo akan menjadi langkah strategis untuk menekan biaya pengiriman dan mempercepat waktu pemrosesan pesanan ke mayoritas pelanggan.
"""